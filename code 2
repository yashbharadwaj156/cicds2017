**Original Code vs GCN Updated Code Comparison**

---

### **1. Data Loading and Preprocessing**

**Before (Original Code):**
```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Load CSV files
df = pd.concat([
    pd.read_csv("/kaggle/input/network-intrusion-dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv"),
    pd.read_csv("/kaggle/input/network-intrusion-dataset/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv"),
    ...
], axis=0)
df.fillna(0, inplace=True)
encoder = LabelEncoder()
df[' Label'] = encoder.fit_transform(df[' Label'])
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df.drop(columns=[' Label']))
y = df[' Label'].values
```

**After (GCN Code):**
```python
from torch_geometric.data import Data
import torch

# Convert labels to numeric
attack_mapping = {
    'BENIGN': 0,
    'DDoS': 1,
    'PortScan': 2,
    'Web Attack': 3,
    'Infiltration': 4
}
df[' Label'] = df[' Label'].map(attack_mapping)

# Create node features
X = torch.tensor(df.drop(columns=[' Label']).values, dtype=torch.float)
y = torch.tensor(df[' Label'].values, dtype=torch.long)

# Create edge index based on source IP similarity
edges = []
for i in range(len(df)):
    for j in range(i+1, len(df)):
        if df.iloc[i][' Source IP'] == df.iloc[j][' Source IP']:
            edges.append([i, j])
edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()

data = Data(x=X, edge_index=edge_index, y=y)
```
---

### **2. Model Definition**

**Before (Original CNN Code):**
```python
from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten

cnn_model = Sequential([
    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_scaled.shape[1], 1)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(len(set(y)), activation='softmax')
])
cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```

**After (GCN Code):**
```python
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
import torch.nn as nn

class GCNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCNModel, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, output_dim)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

model = GCNModel(input_dim=X.shape[1], hidden_dim=64, output_dim=len(set(y)))
```

---

### **3. Model Training**

**Before (Original Code):**
```python
cnn_model.fit(X_scaled, y, batch_size=32, epochs=100)
```

**After (GCN Code):**
```python
import torch.optim as optim

optimizer = optim.Adam(model.parameters(), lr=0.01)
loss_fn = nn.CrossEntropyLoss()

for epoch in range(100):
    optimizer.zero_grad()
    out = model(data)
    loss = loss_fn(out, data.y)
    loss.backward()
    optimizer.step()
    print(f'Epoch {epoch+1}, Loss: {loss.item()}')
```

---

### **4. Model Evaluation**

**Before (Original Code):**
```python
predictions = cnn_model.predict(X_scaled)
```

**After (GCN Code):**
```python
model.eval()
pred = model(data).argmax(dim=1)
print(f'Predicted class: {pred}')
```

---

### **5. Model Saving**

**Before (Original Code):**
```python
cnn_model.save("cnn_model.h5")
```

**After (GCN Code):**
```python
torch.save(model.state_dict(), 'gcn_model.pth')
```

---

**Conclusion:**
This transformation replaces traditional CNN models with a GCN approach, enabling better handling of relationships between network flows through graph-based learning.

__________________________________________________________________________________________________________________________________

**Original Code vs GCN Updated Code Comparison**

---

### **1. Explanation of GCN Model**

**GCN Model Code:**
```python
from torch_geometric.nn import GCNConv
import torch.nn.functional as F
import torch.nn as nn

class GCNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GCNModel, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)  # First graph convolution layer
        self.conv2 = GCNConv(hidden_dim, output_dim) # Second graph convolution layer

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)  # Perform convolution on the input features
        x = F.relu(x)  # Apply ReLU activation function
        x = self.conv2(x, edge_index)  # Perform convolution to obtain final output
        return F.log_softmax(x, dim=1)  # Apply softmax for multi-class classification

model = GCNModel(input_dim=X.shape[1], hidden_dim=64, output_dim=len(set(y)))
```

### **Explanation of Each Line**

1. **`from torch_geometric.nn import GCNConv`**
   - Imports the `GCNConv` layer from PyTorch Geometric, which applies graph convolution operations.

2. **`import torch.nn.functional as F`**
   - Provides activation functions such as `relu` and `softmax`.

3. **`import torch.nn as nn`**
   - Defines the neural network structure.

4. **`class GCNModel(nn.Module):`**
   - Defines the Graph Convolutional Network model as a subclass of PyTorch's `nn.Module`.

5. **`def __init__(self, input_dim, hidden_dim, output_dim):`**
   - Initializes the GCN model with input dimension, hidden layers, and output dimension.

6. **`self.conv1 = GCNConv(input_dim, hidden_dim)`**
   - First GCN layer that transforms input features into a hidden representation.

7. **`self.conv2 = GCNConv(hidden_dim, output_dim)`**
   - Second GCN layer that transforms hidden features into output classes.

8. **`def forward(self, data):`**
   - Defines the forward pass for processing data.

9. **`x, edge_index = data.x, data.edge_index`**
   - Extracts node features `x` and edge index (connections between nodes).

10. **`x = self.conv1(x, edge_index)`**
    - Applies the first graph convolution.

11. **`x = F.relu(x)`**
    - Applies the ReLU activation function to introduce non-linearity.

12. **`x = self.conv2(x, edge_index)`**
    - Applies the second convolutional layer to get class probabilities.

13. **`return F.log_softmax(x, dim=1)`**
    - Computes log-softmax over class probabilities for multi-class classification.

14. **`model = GCNModel(input_dim=X.shape[1], hidden_dim=64, output_dim=len(set(y)))`**
    - Instantiates the GCN model with specified input features, hidden layers, and output classes.

---

### **Comparison with CNN**

| **CNN (Original Code)**          | **GCN (Updated Code)**                |
|----------------------------------|--------------------------------------|
| `Dense` layers for full connectivity | `GCNConv` for graph-based learning    |
| Neurons are connected in layers    | Nodes connected based on graph edges |
| `relu` activation per layer        | `relu` applied after convolution     |
| Flattening of data                  | No need for flattening, structure preserved |

---

**Conclusion:**
GCN models do not use traditional dense layers because they operate on graphs where connections are represented explicitly using adjacency matrices rather than implicit fully connected layers, making them more efficient for relational data.

_________________________________________________________________________________________________________________________________



  **Original Code vs GCN Updated Code Comparison**

---

### **1. Explanation of Data Transformation to Graph Format**

**GCN Data Preparation Code:**
```python
import torch

# Convert labels to numeric
attack_mapping = {
    'BENIGN': 0,
    'DDoS': 1,
    'PortScan': 2,
    'Web Attack': 3,
    'Infiltration': 4
}
df[' Label'] = df[' Label'].map(attack_mapping)

# Create node features
X = torch.tensor(df.drop(columns=[' Label']).values, dtype=torch.float)
y = torch.tensor(df[' Label'].values, dtype=torch.long)

# Create edge index based on source IP similarity
edges = []
for i in range(len(df)):
    for j in range(i+1, len(df)):
        if df.iloc[i][' Source IP'] == df.iloc[j][' Source IP']:
            edges.append([i, j])
edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()

data = Data(x=X, edge_index=edge_index, y=y)
```

### **Explanation of Each Line**

1. **`import torch`**
   - Imports PyTorch, which is used for tensor operations and deep learning model development.

2. **`attack_mapping = {...}`**
   - Creates a dictionary to map categorical attack types into numerical values.
   - Background: Converts string labels (e.g., 'BENIGN') into numerical values to be used in the model.
   - Different from original code: Instead of using `LabelEncoder`, we manually define mappings to ensure specific class ordering.

3. **`df[' Label'] = df[' Label'].map(attack_mapping)`**
   - Applies the mapping to convert labels from string values to integers.

4. **`X = torch.tensor(df.drop(columns=[' Label']).values, dtype=torch.float)`**
   - Converts all features (except labels) to a PyTorch tensor with float data type.
   - Background: PyTorch tensors enable efficient computations and are compatible with GCN models.
   - Different from original code: Previously, feature scaling was applied using `StandardScaler` but GCNs don't require feature scaling.

5. **`y = torch.tensor(df[' Label'].values, dtype=torch.long)`**
   - Converts the labels to PyTorch tensors with long integer type, which is required for classification tasks.

6. **Edge Construction:**
   ```python
   edges = []
   for i in range(len(df)):
       for j in range(i+1, len(df)):
           if df.iloc[i][' Source IP'] == df.iloc[j][' Source IP']:
               edges.append([i, j])
   ```
   - Creates graph edges based on the condition that rows with the same `Source IP` should be connected.
   - Background: This simulates network traffic relationships where packets from the same source should be considered linked.
   - Different from original code: Traditional models assume independent samples, whereas GCN exploits relationships between data points.

7. **`edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()`**
   - Converts the list of edges into a PyTorch tensor.
   - `.t()` transposes the tensor to match the required format of `[2, num_edges]`.
   - `.contiguous()` ensures memory alignment for efficient processing.

8. **`data = Data(x=X, edge_index=edge_index, y=y)`**
   - Combines node features `x`, edges `edge_index`, and labels `y` into a PyTorch Geometric `Data` object.
   - Background: This object is required by PyTorch Geometric to process graph-based data efficiently.

---

### **Key Differences from Original Code**

| **Original Code (Tabular Processing)**      | **GCN Updated Code (Graph Processing)**       |
|---------------------------------------------|------------------------------------------------|
| Uses `LabelEncoder()` for categorical labels | Uses manual label mapping for better control   |
| Feature scaling with `StandardScaler()`      | No scaling needed; uses raw numerical values   |
| Data processed independently                 | Data processed with relationships (edges)     |
| CNN expects image-like inputs                | GCN expects graph-structured data              |

---

**Conclusion:**
By transforming the dataset into a graph format, GCN can better capture the relationships between network events, providing richer insights compared to traditional ML approaches.

